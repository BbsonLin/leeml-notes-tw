# 分類(Classification)

![](res/chapter8-1.png)

分类要找一个函数(Function)，输入对象 $x$ 特征，输出是该对象属于 n 个类别中是属于哪一个。

## 實際應用

- 信用評分 (二元分類問題)
    - 輸入：收入，儲蓄，行業，年齡，金融史…
    - 輸出：是否拒絕拒絕貸款
- 醫療診斷 (多元分類問題)
    - 輸入：當前症狀，年齡，性別，醫療史…
    - 輸出：患了哪種疾病
- 手寫文字辨識 (多元分類問題)
    - 輸入：手寫的文字
    - 輸出：約9353個漢字中輸入哪一個
    ![](res/chapter8-2.png)
- 人臉辨識


## 寶可夢屬性分類

首先認識一下寶可夢中的屬性分類：
![](res/chapter8-3.png)

寶可夢有很多的屬性，比如電，火，水。要做的就是一個分類的問題：需要找到一個函數，

- 輸入：一隻寶可夢的特徵（整體強度，生命值，攻擊力，防禦力，特殊攻擊力，特殊防禦力，速度等）
- 輸出：屬於哪一種類型的寶可夢

首先將寶可夢數值化：以皮卡丘為例

- Total：整體強度，大概的表述寶可夢有多強，320
- HP：生命值，35
- Attack：攻擊力，55
- Defense：防禦力，40
- SP Atk：特殊攻擊力，50
- SP Def：特殊防禦力，50
- Speed：速度，90

所以我們可以將一隻寶可夢用一個 7 個數字組成的向量座表示。

做這有什麼用呢? 可以預測對手出現了一隻不在圖鑑上的寶可夢屬性，並依照下圖，做出戰略的對應。

![](res/chapter8-4.png)

### 如何做到分類?

#### 將分類問題(Classification) 視作迴歸問題(Regression)?

舉一個二元分類(binary classification)的例子，假設輸入神奇寶貝的特徵 $x$，判斷屬於 Class1 或者 Class2，把這個當作迴歸問題。

- Class1：相當於 target 是 1。
- Class2：相當於 target 是 -1。

然後訓練模型：因為做完迴歸會是個數值，如果數值比較接近 1，就當作 Class1，如果數值接近 -1，就當做 Class2。

然而，這樣做遇到什麼問題呢？

![](res/chapter8-5.png)

- 左圖：綠色是分界線，紅色叉叉就是 Class2 的類別，藍色圈圈就是 Class1 的類別。
- 右圖：紫色是分界線，紅色叉叉就是 Class2 的類別，藍色圈圈就是 Class1 的類別。訓練集添加有很多的距離遠大於1 的資料後，分界線從綠色偏移到紫色

右圖用迴歸的方式硬訓練可能會得到紫色的這條，直觀上就是將綠色的線偏移一點到紫色的時候，就能讓右下角的那部分的值不是那麼大；但顯然實際上是綠色的才是比較好的。

**此時可以得出用迴歸的方式來處理分類問題是不適用的。**(因為迴歸方式會懲罰那些太正確的資料。)

另外有人也會用迴歸方式處理多分類問題，Class1 當作 target 是 1，Class2 當作 target 是 2， Class3 當作 target 是 3 ...。

如果這樣做的話，就會預設 Class2 和 Class3 是比較接近的，認為它們是有某種關係的；Class1 和 Class2 也是有某種關係。但是實際上這種關係不存在的時候，是沒有辦法得到好的結果。(**並不推薦這麼做**)

#### 理想方法

![](res/chapter8-6.png)

* 考慮二元分類，希望在模型中找到一個函數，帶入 $x$ 大於 0 時就是 Class 1，否則就是 Class 2。
* 其損失函數就定義為在訓練集上面預測的錯誤次數加總。

但就我們目前的學到的方式是無法做到的，因為以上定義出來的函數都是不可微分的，意味著無法用梯度下降法(GD)...

> 實際上是有方式可以達成，如 Perceptron (感知器), SVM

---

不過還是有別種方法，我們先以機率的觀點來看待分類問題。

### 機率觀點看待分類問題

#### 抽球機率問題

假設有兩個盒子，各裝了5個球，$2/3$ 的機率會選擇從 盒子1 抽球 ，$1/3$ 的機率會從 盒子2 抽球。

而從盒子中藍色球和綠色球的分配可以得到：

- 在 盒子1 中隨機抽一個球，是藍色球機率為 $4/5$，綠色球機率為 $1/5$
- 在 盒子2 中隨機抽一個球，是藍色球機率為 $2/5$，綠色球機率為 $3/5$

![](res/chapter8-7.png)

現在求隨機從兩個盒子中抽一個球，抽到的是 盒子1 中藍色球的機率是多少？

$
\begin{aligned} 
P(B_1|Blue) &= \frac{P(Blue|B_1)P(B_1)}{P(Blue|B_1)P(B_1)+P(Blue|B_2)P(B_2) } \\
& = \cfrac{\cfrac{4}{5} * \cfrac{2}{3}}{\cfrac{4}{5} * \cfrac{2}{3}+\cfrac{2}{5}* \cfrac{1}{3}} 
= \cfrac{4}{5}
\end{aligned} 
$


#### 機率與分類

將抽球機率置換成分類機率，假設我們資料分成了如下圖的兩類，Class1 和 Class2。

![](res/chapter8-8.png)

如果知道上圖紅框內四種機率值，我可以推導出:

$P(C_1|x) = \cfrac{ P(x|C_1)P(C_1)} {P(x|C_1)P(C_1) + P(x|C_2)P(C_2) }$

> $P(C_1)$: 資料從 Class1 選的機率。  
> $P(C_2)$: 資料從 Class2 選的機率。  
> $P(x|C_1)$: 從 Class1 選出資料 $x$ 的機率。  
> $P(x|C_2)$: 從 Class2 選出資料 $x$ 的機率。  
> $P(C_1|x)$: 從全部的資料中選出來的 $x$，是從 Class1 中選出來的機率；也代表著資料 $x$ 被分類成 Class1 的機率。

而我們希望從訓練集中，把上圖中的四個機率值估測出來，這一整套想法稱作**生成模型**(Generative Model)。

--

為何稱作**生成模型**? 

因為有這個模型，就能生成 $x$，並計算其生成的機率 $P(x)$。

$P(x) = P(x|C_1)P(C_1) + P(x|C_2)P(C_2)$

> $P(x)$: 從全部的資料中選出 $x$ 的機率。  


### 寶可夢分類問題

![](res/chapter8-9.png)

先考慮簡單的寶可夢二分類，水系或者一般系，通過訓練集的數據可以計算出 $P(C_1)$ 和 $P(C_2)$，如圖所示：

- 水系佔比：$P(C_1) = 0.56$
- 一般系佔比：$P(C_2) = 0.44$

--

接下來我們想計算沒見過的海龜(寶可夢)是水系的機率，即 $P(x|C_1)$。

在模型中，每隻寶可夢，我們輸入的是寶可夢的能力數值，為一個特徵向量(vector)。

![](res/chapter8-10.png)

--

於是我們將寶可夢資料，依照 `Defense` 和 `SP Defense` 這兩個數值可視化。

![](res/chapter8-11.png)

不過從上圖中，我們怎麼估測海龜是水系的機率呢?

我們可以想像訓練集的水系寶可夢，只是眾多資料的冰山一角，是從一個常態機率分布(**高斯分布**)裡面取樣 79 個出來的。


### 高斯分布(Gaussian distribution)

![](res/chapter8-12.png)

> $x$: 輸入向量。  
> $f_{\mu,\Sigma}(x)$: 輸出機率密度(probability density)，與機率成正比。  
> $\mu$: 平均數向量 (mean)  
> $\Sigma$: 共變異數矩陣 (covariance matrix)

![](res/chapter8-13.png)

$\mu$ 相同，$\Sigma$ 不同

![](res/chapter8-14.png)

$\mu$ 不同，$\Sigma$ 相同

![](res/chapter8-15.png)

假設通過 79 個點估測出了 $\mu$ 和 $\Sigma$。$\mu$ 是圖中的黃色點，$\Sigma$ 是紅色的範圍。

給一個不在 79 個點之內的新點，就可以用剛才估測出的 $\mu$ 和 $\Sigma$ 寫出高斯分佈的函數 $f_{\mu,\Sigma}(x)$，然後把 $x$ 帶進去，計算出被挑選出來的機率。


### 最大似然值

如何找高斯分佈函數中的 $\mu$ 和 $\Sigma$ 呢?
